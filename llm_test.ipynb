{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLM.llm import EmotionAnalyzer\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "user_id = \"U211\"\n",
    "mode = \"daily\"\n",
    "test_diary = '2024-6-18\\n晨跑时撞见梧桐树下练太极的老人们，白衣随动作翻飞如鸽群，收势时齐齐朝我点头微笑，仿佛整条街道都在呼吸。拐角早餐铺的油墩子涨价五毛，老板娘硬塞给我两个刚炸的南瓜饼：\"年轻人流汗多，补补糖分。\"午后在旧书店消磨时光，发现1987年版《上海滩》连环画夹着张泛黄的粮票。戴圆框眼镜的店主正给流浪猫读《追忆似水年华》，阳光斜切过书架，灰尘在光柱里跳探戈。突然收到航空公司升舱短信，才想起三年前囤的里程快过期——那些计划着去冰岛看极光的夜晚，原来和罐头一样有保质期。暮色里帮邻居修智能门锁，00后男孩递来的工具箱贴着奥特曼贴纸。他抱怨元宇宙课程作业要建\"赛博弄堂\"，却说不清石库门砖缝里的青苔该怎么用代码渲染。回家时电梯镜面映出四张相似的疲惫面孔，我们默契地数着楼层数字，在\"叮\"的一声里各自溶解进防盗门后的灯火。'\n",
    "date = datetime(2025, 6, 15, 14, 30, 0)\n",
    "\n",
    "analyze = EmotionAnalyzer(user_id)\n",
    "result = analyze.analyze(mode, test_diary, date)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 正在创建/访问用户目录：/Users/coffee/Work/VsCode/web_for_Inksoul/data_base/diary_db/U985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 23:07:24,160 - EmotionAnalyzer.U985 - INFO - [SUCCESS] 日记已保存（时间：2025-06-15 14:35:00）\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存的日记日期： ['2025-06-15']\n"
     ]
    }
   ],
   "source": [
    "from LLM.llm import EmotionAnalyzer\n",
    "from datetime import datetime\n",
    "\n",
    "user_id = \"U985\"\n",
    "date = datetime(2025, 6, 15, 14, 35, 0)\n",
    "diary = '2024-6-15\\n地铁早高峰有人外放短视频，循环播放\"挖呀挖\"神曲。前排穿灰西装的大哥公文包上粘着幼儿园贴纸，屏幕里浮动的K线图和包上歪扭的太阳花构成荒诞对冲。出站时踩到湿漉漉的银杏果，腐坏的气味像被踩碎的秋天。午休溜去新开的无人超市，冷柜里沙拉包装上印着\"数字游牧套餐\"，扫码时机器突然播报：\"您本周摄入纤维不足，建议加购羽衣甘蓝汁。\" 货架深处的AI摄像头闪着蓝光，恍惚觉得不是我在挑选商品，是算法在喂养数据。'\n",
    "\n",
    "analyze = EmotionAnalyzer(user_id)  # 创建新实例\n",
    "log_result = analyze.log_diary(diary, date.timestamp())\n",
    "print(\"已保存的日记日期：\", analyze.get_diary_dates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 正在创建/访问用户目录：/Users/coffee/Work/VsCode/web_for_Inksoul/data_base/diary_db/U985\n",
      "已保存的日记日期： ['2025-06-15']\n",
      "start_date: 2025-06-01 00:00:00 end_date: 2025-06-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'diary_review': '过去这段时间里，您的生活充满了对日常细节的敏锐观察和复杂的情感反应。从地铁早高峰的嘈杂到无人超市的科技感，您既在都市生活的荒诞中捕捉到微妙的诗意（如灰西装上的幼儿园贴纸），也在数字化服务中感受到被算法支配的疏离感（AI摄像头与营养建议的突兀提示）。这些片段展现了您对现代生活矛盾性的深刻感知。', 'emotional_basis': {'喜悦': 10, '信任': 15, '害怕': 25, '惊讶': 30, '难过': 20, '厌恶': 35, '生气': 15, '期待': 10}, 'domain_event': {'2024-6-15': {'event': '地铁早高峰遭遇外放短视频与无人超市的数字化体验', 'emotion': '荒诞与疏离'}}, 'emotion_trend': '情绪呈现明显的矛盾性，既有对都市生活荒诞性的敏锐觉察（如银杏果腐坏气味的伤感联想），又夹杂着对科技侵入日常的警惕（AI摄像头的监控感）。厌恶和惊讶是主导情绪，但底层流动着对人性化连接的隐约渴望（如注意到西装大哥的幼儿园贴纸）。', 'weekly_advice': \"建议每天寻找一个'反算法时刻'：比如周三用现金购买午餐而非扫码支付，周五选择纸质书而非电子阅读。周末可尝试拜访传统菜市场，观察摊主与顾客的自然互动。这些行为能帮助您重新建立对生活的主导感，平衡数字化带来的异化体验。\", 'event_key_words': {'都市荒诞': 75, '科技侵入': 80, '感官触发': 65, '人性细节': 60, '数字化服务': 70, '环境异味': 45, '行为观察': 55, '符号对冲': 50}, 'emotion_key_words': {'疏离感': 70, '警惕性': 65, '荒诞幽默': 40, '怀旧伤感': 50, '被动感': 75, '观察欲': 60, '矛盾感': 55, '控制缺失': 45}, 'famous_quote': '「现代人对自己生活的异化，最痛苦的莫过于发现自己既用着最先进的工具，却又在精神上无家可归。」——韩炳哲《精神政治学》'}\n"
     ]
    }
   ],
   "source": [
    "from LLM.llm import EmotionAnalyzer\n",
    "from datetime import datetime\n",
    "\n",
    "user_id = \"U985\"\n",
    "mode = \"weekly\"\n",
    "start_date = datetime(2025, 6, 1)\n",
    "end_date = datetime(2025, 6, 16)\n",
    "\n",
    "analyze = EmotionAnalyzer(user_id)\n",
    "print(\"已保存的日记日期：\", analyze.get_diary_dates())\n",
    "\n",
    "# 指定日期模式\n",
    "result = analyze.analyze(\n",
    "    mode = mode, \n",
    "    start_date=start_date, \n",
    "    end_date=end_date)\n",
    "print(result)\n",
    "\n",
    "# 默认日期模式（过去7天）\n",
    "# result = analyze.analyze(\n",
    "#     mode = mode, \n",
    "# )\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 23:07:20,034 - EmotionAnalyzer.U985 - INFO - [SUCCESS] 已删除 2025-06-15 14:35:00 的日记 (ID: ['838223cd-89b5-4d0d-a955-d2dc49cf7673'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 正在创建/访问用户目录：/Users/coffee/Work/VsCode/web_for_Inksoul/data_base/diary_db/U985\n",
      "已保存的日记日期： ['2025-06-15']\n",
      "{'status': 'success', 'message': '日记删除成功', 'deleted_time': '2025-06-15T14:35:00', 'deleted_ids': ['838223cd-89b5-4d0d-a955-d2dc49cf7673']}\n",
      "已保存的日记日期： []\n"
     ]
    }
   ],
   "source": [
    "from LLM.llm import EmotionAnalyzer\n",
    "from datetime import datetime\n",
    "\n",
    "user_id = \"U985\"\n",
    "date = datetime(2025, 6, 15, 14, 35, 0)\n",
    "\n",
    "analyze = EmotionAnalyzer(user_id)  # 创建新实例\n",
    "print(\"已保存的日记日期：\", analyze.get_diary_dates())\n",
    "delete_result = analyze.delete_diary(date)\n",
    "print(delete_result)\n",
    "print(\"已保存的日记日期：\", analyze.get_diary_dates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from LLM.llm import EmotionAnalyzer\n",
    "from datetime import datetime\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "user_id = \"U985\"\n",
    "date = datetime(2025, 6, 15, 14, 35, 0)\n",
    "diary = '2024-6-15\\n地铁早高峰有人外放短视频，循环播放\"挖呀挖\"神曲。前排穿灰西装的大哥公文包上粘着幼儿园贴纸，屏幕里浮动的K线图和包上歪扭的太阳花构成荒诞对冲。出站时踩到湿漉漉的银杏果，腐坏的气味像被踩碎的秋天。午休溜去新开的无人超市，冷柜里沙拉包装上印着\"数字游牧套餐\"，扫码时机器突然播报：\"您本周摄入纤维不足，建议加购羽衣甘蓝汁。\" 货架深处的AI摄像头闪着蓝光，恍惚觉得不是我在挑选商品，是算法在喂养数据。'\n",
    "\n",
    "# 创建分析器实例\n",
    "analyze = EmotionAnalyzer(user_id)\n",
    "\n",
    "# 测试加密和解密\n",
    "db = analyze.db\n",
    "encrypted = db._encrypt_text(diary)\n",
    "print(\"加密后的数据：\")\n",
    "print(json.loads(encrypted))  # 应该显示一个包含 nonce、ciphertext 和 tag 的字典\n",
    "\n",
    "decrypted = db._decrypt_text(encrypted)\n",
    "print(\"\\n解密后的文本是否与原文相同：\", decrypted == diary)\n",
    "\n",
    "# 保存日记\n",
    "log_result = analyze.log_diary(diary, date.timestamp())\n",
    "\n",
    "# 检索日记\n",
    "retrieved = analyze._retrieve_diaries(\"daily\", query=diary)\n",
    "print(\"\\n检索到的日记：\", retrieved[:100], \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
